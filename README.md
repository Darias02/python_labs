# python_labs
# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 1
## –ó–∞–¥–∞–Ω–∏–µ 1
![–ö–æ–¥:](./images/lab01/01.png)
![–í—ã–≤–æ–¥:](./images/lab01/01r.png)

## –ó–∞–¥–∞–Ω–∏–µ 2
![–ö–æ–¥:](./images/lab01/02.png)
![–í—ã–≤–æ–¥:](./images/lab01/02r.png)

## –ó–∞–¥–∞–Ω–∏–µ 3
![–ö–æ–¥:](./images/lab01/03.png)
![–í—ã–≤–æ–¥:](./images/lab01/03r.png)

## –ó–∞–¥–∞–Ω–∏–µ 4
![–ö–æ–¥:](./images/lab01/04.png)
![–í—ã–≤–æ–¥:](./images/lab01/04r.png)

## –ó–∞–¥–∞–Ω–∏–µ 5
![–ö–æ–¥:](./images/lab01/05.png)
![–í—ã–≤–æ–¥:](./images/lab01/05r.png)

## –ó–∞–¥–∞–Ω–∏–µ 6
![–ö–æ–¥:](./images/lab01/06.png)
![–í—ã–≤–æ–¥:](./images/lab01/06r.png)

## –ó–∞–¥–∞–Ω–∏–µ 7
![–ö–æ–¥:](images/lab01/07.png)
![–í—ã–≤–æ–¥:](./images/lab01/07r.png)

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 2

## –ó–∞–¥–∞–Ω–∏–µ 1 - arrays
### min_max
```python
test_m_m = [
    [3, -1, 5, 5, 0],
    [42],
    [-5, -2, -9],
    [],
    [1.5, 2, 2.0, -3.1]
]
def min_max(nums: list[float | int]) -> tuple[float | int, float | int]:
    if len(nums) == 0: 
        return 'ValueError'
    return (min(nums), max(nums)) 
for i in test_m_m:
    print(min_max(i))
```
### unique_sorted
```python
test_u_s = [
    [3, 1, 2, 1, 3],
    [],
    [-1, -1, 0, 2, 2],
    [1.0, 1, 2.5, 2.5, 0]
]
def unique_sorted(nums2: list[float | int]) -> list[float | int]:
    if len(nums2) == 0: 
        return 'ValueError'
    return sorted(set(nums2))
for i in test_u_s:
    print(unique_sorted(i))
```

### flatten
```python
fl_test = [
    [[1, 2], [3, 4]],
    ([1, 2], (3, 4, 5)),
    [[1], [], [2, 3]],
    [[1, 2], "ab"]
]
def flatten(mat: list[list | tuple]) -> list:
    result = []
    for a in mat:
        if isinstance(a, (list, tuple)): result.extend(flatten(a))
        else:
            if type(a) == int or type(a) == float: result.append(a)
            else: return 'TypeError'
    return result
for i in fl_test:
    print(flatten(i))
```
![–í—ã–≤–æ–¥:](./images/lab02/1x.png)

## –ó–∞–¥–∞–Ω–∏–µ 2 - matrix
### transpose
```python

test_t = [
    [[1, 2, 3]],
    [[1], [2], [3]],
    [[1, 2], [3, 4]],
    [],
    [[1, 2], [3]]
]


def transpose(mat: list[list[float | int]]) -> list[list]:
    if not mat:
        return []
    len_mat = len(mat[0])
    for i in mat:
        if len(i) != len_mat:
            return 'ValueError'

    len_column = len(mat[0]) 
    result_t = [[] for _ in range(len_column)]
    
    for str in range(len(mat)): 
        for column in range(len_column):  
            result_t[column].append(mat[str][column])  
    
    return result_t

for i in test_t:
    print(transpose(i))
```
### row_sums
```python
test_rs = [
    [[1, 2, 3], [4, 5, 6]],
    [[-1, 1], [10, -10]],
    [[0, 0], [0, 0]],
    [[1, 2], [3]]
]


def row_sums(mat: list[list[float | int]]) -> list[float]:
    res = []
    len_column = len(mat[0])
    for i in mat:
        if len(i) != len_column:
            return 'ValueError'
    for row in mat:
        row_sum = sum(row)
        res.append(row_sum)
    return res
for i in test_rs:
    print(row_sums(i))
```



### col_sums
```python
test_cs = [
    [[1, 2, 3], [4, 5, 6]],
    [[-1, 1], [10, -10]],
    [[0, 0], [0, 0]],
    [[1, 2], [3]]
]

def col_sums(mat: list[list[float | int]]) -> list[float]:
    result_cs = []
    len_str = len(mat[0])
    result_cs = [0] * len_str
    for i in mat:
        if len(i) != len_str:
            return 'ValueError'
        
    for column in mat:
        k = 0
        for strok in column:
            result_cs[k%len_str] = result_cs[k%len_str] + strok
            k+=1
    return result_cs
for i in test_cs:
    print(col_sums(i))
```

![–í—ã–≤–æ–¥:](./images/lab01/02r.png)

## –ó–∞–¥–∞–Ω–∏–µ 3 - tuples
```python
test_input = [
    ("–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á", "BIVT-25", 4.6),
    ("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä", "IKBO-12", 5.0),
    ("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä –ü–µ—Ç—Ä–æ–≤–∏—á", "IKBO-12", 5.0),
    ("  —Å–∏–¥–æ—Ä–æ–≤–∞  –∞–Ω–Ω–∞   —Å–µ—Ä–≥–µ–µ–≤–Ω–∞ ", "ABB-01", 3.999), 
    (' FJJ ', 'RR'),
    ('WER', 'Det', 52), 
    ('qw', '', 53.9)
]
def format_record(rec: tuple[str, str, float]) -> str: 
    if not isinstance(rec[2], float):
        return TypeError
    try: 
        len(rec)!= 3 or type(rec[0]) != str or type(rec[1]) != str or type(rec[2]) != float or len(rec[0])==0 or len(rec[1])==0 
    
        name, gr, gpa = rec
    
        name = name.split()
        if len(name) == 3: name = f'{name[0].title()} {name[1][0].upper()}.{name[1][0].upper()}.'
        else: name = f'{name[0].title()} {name[1][0].upper()}.'
        return f'{name}, –≥—Ä. {gr}, GPA {gpa}'
    except:
        return TypeError

for i in test_input:
    print(format_record(i))
```
![–í—ã–≤–æ–¥:](./images/lab02/3x.png)


# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 3
## text.py
* _—Ñ–∞–π–ª –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–π_
```python
import re  

def normalize(text: str, *, casefold: bool = True, replacement: bool = True) -> str:
    if not text:
        return ''
    
    
    if casefold:
        text = text.casefold()
    
    if replacement:
        text = text.replace('—ë', '–µ').replace('–Å', '–ï')
    
    text = text.replace('\t', ' ').replace('\r', ' ').replace('\n', ' ')
    
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text


def tokenize(text: str) -> list[str]:
    if not text:
        return []
    pattern = r'\w+(?:-\w+)*'
    tokens = re.findall(pattern, text)
    
    return tokens

def count_freq(tokens: list[str]) -> dict[str, int]:
    freq_dict = {}
    
    for token in tokens:
        freq_dict[token] = freq_dict.get(token, 0) + 1
    return freq_dict  

def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    items = list(freq.items())
    sorted_items = sorted(items, key=lambda x: (-x[1], x[0]))
    return sorted_items[:n]
```
## text_stats.py
* _—Ñ–∞–π–ª —Å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π —Ñ—É–Ω–∫—Ü–∏–π_
```python
iimport sys
import os

sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'lib'))
from text import normalize, tokenize, count_freq, top_n

sys.path.append(os.path.join(os.path.dirname(__file__)))
from test import normalize_test, tokenize_test, count_freq__top_n_test


for i in normalize_test:
    print(normalize(i))
for i in tokenize_test:
    print(tokenize(i))
for i in count_freq__top_n_test:
    print(count_freq(i))
    print(top_n(count_freq(i)))


def main():
    text = sys.stdin.readline().strip()  
    if not text:
        print("–í—Å–µ–≥–æ —Å–ª–æ–≤: 0")
        print("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: 0")
        print("–¢–æ–ø-5:")
        return
    
    normalized = normalize(text)
    tokens = tokenize(normalized)
    
    total = len(tokens)
    unique = len(set(tokens))
    freq_dict = count_freq(tokens)
    top_words = top_n(freq_dict, 5)
    
    print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {total}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {unique}")
    print(f"–¢–æ–ø-{min(5, len(set(tokens)))}:")
    for word, count in top_words:
        print(f"{word}:{count}")

if __name__ == "__main__":
    main()

```
### test.py
* _—Ñ–∞–π–ª —Å —Ç–µ—Å—Ç–∞–º–∏_
```python
normalize_test = [
    "–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t",
    "—ë–∂–∏–∫, –Å–ª–∫–∞",
    "Hello\r\nWorld",
    "  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  "
]


tokenize_test = [
    "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä",
    "hello,world!!!",
    "–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ",
    "2025 –≥–æ–¥",
    "emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ"
] 


count_freq__top_n_test = [
    ["a","b","a","c","b","a"],
    ["bb","aa","bb","aa","cc"]
]

```


#### –í—ã–≤–æ–¥:
![–í—ã–≤–æ–¥:](./images/lab03/img.png)

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 4


## —Ñ–∞–π–ª io_txt_cvs.py
```python
import csv
from pathlib import Path #–¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø—É—Ç—è–º–∏ —Ñ–∞–π–ª–æ–≤
from typing import Iterable, Sequence

def read_text(path: str | Path, encoding: str = 'utf-8') -> str: #—á—Ç–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞
    path = Path(path)
    return path.read_text(encoding=encoding)




def write_csv(rows: Iterable[Sequence], path: str | Path, header: tuple[str, ...] | None = None) -> None:
    p = Path(path)
    rows = list(rows)
    if rows:
        first_len = len(rows[0])
        for i, roww in enumerate(rows): #–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω–¥–µ–∫—Å, —ç–ª–µ–º–µ–Ω—Ç
            if len(roww) != first_len:
                raise ValueError(f'–°—Ç—Ä–æ–∫–∞ {i} –∏–º–µ–µ—Ç –¥–ª–∏–Ω—É {len(roww)}, –æ–∂–∏–¥–∞–ª–æ—Å—å {first_len}') 
            
    with p.open('w', newline='', encoding='utf-8') as f: #–æ—Ç–∫—Ä—ã—Ç–∏–µ —Ñ–∞–π–ª–∞ –¥–ª—è –∑–∞–ø–∏—Å–∏
        w = csv.writer(f)
        if header is not None: #e—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω –∑–∞–≥–æ–ª–æ–≤–æ–∫
            w.writerow(header)
        for r in rows:
            w.writerow(r)



if __name__ == '__main__':
    print('—Ç–µ—Å—Ç')
    try:
        txt = read_text('data/lab04/input.txt')  # –¥–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å —Å—Ç—Ä–æ–∫—É
        print(f'–ü—Ä–æ—á–∏—Ç–∞–Ω–æ {len(txt)} —Å–∏–º–≤–æ–ª–æ–≤')
        print(f'–ü–µ—Ä–≤—ã–µ 50 —Å–∏–º–≤–æ–ª–æ–≤: {txt[:50]}')
    except FileNotFoundError:
        print('–§–∞–π–ª –Ω–µ –Ω–≤–π–¥–µ–Ω')
    except Exception as e:
        print('–æ—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏')
    
    try:
        write_csv([('word','count'),('test',3)], 'data/check.csv')  # —Å–æ–∑–¥–∞—Å—Ç CSV
    except Exception as e:
        print('–æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ CSV')
```


## —Ñ–∞–π–ª text_report.py
```python
port sys
from pathlib import Path
from collections import Counter 
sys.path.insert(0, str((Path(__file__).parent.parent))) #–¥–æ–±–∞–≤–ª—è—Ç –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ –Ω–∞—á–∞–ª–æ —Å–ø–∏—Å–∫–∞
from lib.text import normalize, tokenize, top_n
from lab04.io_txt_csv import read_text, write_csv
def frequencies_from_text(text: str) -> dict[str, int]: #–ø–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —á–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤
    tokens = tokenize(normalize(text))
    return Counter(tokens) 

def sorted_word_counts(freq: dict[str, int]) -> list[tuple[str, int]]: #—Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —É–±—ã–≤–∞–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã, –ø–æ –∞–≤—Ñ–∞–≤–∏—Ç—É
    return sorted(freq.items(), key=lambda kv: (-kv[1], kv[0]))
def report(input_path: Path, output_path: Path, encoding: str = 'utf-8') -> dict[str, int]: #–æ—á—Ç—ë—Ç
    try:
        text = read_text(input_path, encoding=encoding)
        if not text.strip():
            print('—Ñ–∞–π–ª –ø—É—Å—Ç–æ–π')
            header = ('word', 'count')
            write_csv([], output_path, header)  # –¢–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫
            return {}
        
        
        freq = frequencies_from_text(text)
        sorted_counts = sorted_word_counts(freq)
        header = ('word', 'count') #–∑–∞–≥–æ–ª–æ–≤–æ–∫
        write_csv(sorted_counts, output_path, header)
        return freq
    except FileNotFoundError:
        print(f'FileNotFoundError')
        sys.exit(1) #–∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã —Å –æ—à–∏–±–∫–æ–π
        
    except Exception as e:
        print(f'–æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {e}')
        sys.exit(1)



def main():
    input_file = Path('data/lab04/input.txt')
    output_file = Path('data/lab04/report.csv') #–ø—É—Ç—å –¥–ª—è –≤—ã—Ö–æ–¥–∞
    print(f'...–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {input_file}')
    try:
        frequencies = report(input_file, output_file)
        sum_words = sum(frequencies.values()) #–∫–æ–ª-–≤–æ —Å–ª–æ–≤
        unique_words = len(frequencies) #–∫–æ–ª-–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤
        top_words = top_n(frequencies, 5)
        
        print(f'–í—Å–µ–≥–æ —Å–ª–æ–≤: {sum_words}')
        print(f'–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {unique_words}')
        print('–¢–æ–ø-5:')

        for word, count in top_words:
            print(f'  {word}: {count}')
    except Exception as e:
        print(f'–æ—à–∏–±–∫–∞ {e}')



if __name__ == '__main__':
    main()
```


## –∑–∞–ø—É—Å–∫ '–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä! –ü—Ä–∏–≤–µ—Ç!!!':

![–í—ã–≤–æ–¥:](./images/lab04/1.png)


![–í—ã–≤–æ–¥:](./images/lab04/1x.png)


![–í—ã–≤–æ–¥:](./images/lab04/1xx.png)
## –∑–∞–ø—É—Å–∫ —Å –ø—É—Å—Ç—ã–º —Ñ–∞–π–ª–æ–º input.txt:

![–í—ã–≤–æ–¥:](./images/lab04/2.png)


![–í—ã–≤–æ–¥:](./images/lab04/2x.png)


![–í—ã–≤–æ–¥:](./images/lab04/2xx.png)

## –∑–∞–ø—É—Å–∫ —Å –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ–º —Ñ–∞–π–ª–∞ input.txt:

![–í—ã–≤–æ–¥:](./images/lab04/0.png)
