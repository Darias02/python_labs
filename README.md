# python_labs
# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 1
## –ó–∞–¥–∞–Ω–∏–µ 1
![–ö–æ–¥:](./images/lab01/01.png)
![–í—ã–≤–æ–¥:](./images/lab01/01r.png)

## –ó–∞–¥–∞–Ω–∏–µ 2
![–ö–æ–¥:](./images/lab01/02.png)
![–í—ã–≤–æ–¥:](./images/lab01/02r.png)

## –ó–∞–¥–∞–Ω–∏–µ 3
![–ö–æ–¥:](./images/lab01/03.png)
![–í—ã–≤–æ–¥:](./images/lab01/03r.png)

## –ó–∞–¥–∞–Ω–∏–µ 4
![–ö–æ–¥:](./images/lab01/04.png)
![–í—ã–≤–æ–¥:](./images/lab01/04r.png)

## –ó–∞–¥–∞–Ω–∏–µ 5
![–ö–æ–¥:](./images/lab01/05.png)
![–í—ã–≤–æ–¥:](./images/lab01/05r.png)

## –ó–∞–¥–∞–Ω–∏–µ 6
![–ö–æ–¥:](./images/lab01/06.png)
![–í—ã–≤–æ–¥:](./images/lab01/06r.png)

## –ó–∞–¥–∞–Ω–∏–µ 7
![–ö–æ–¥:](images/lab01/07.png)
![–í—ã–≤–æ–¥:](./images/lab01/07r.png)

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 2

## –ó–∞–¥–∞–Ω–∏–µ 1 - arrays
### min_max
```python
test_m_m = [
    [3, -1, 5, 5, 0],
    [42],
    [-5, -2, -9],
    [],
    [1.5, 2, 2.0, -3.1]
]
def min_max(nums: list[float | int]) -> tuple[float | int, float | int]:
    if len(nums) == 0: 
        return 'ValueError'
    return (min(nums), max(nums)) 
for i in test_m_m:
    print(min_max(i))
```
### unique_sorted
```python
test_u_s = [
    [3, 1, 2, 1, 3],
    [],
    [-1, -1, 0, 2, 2],
    [1.0, 1, 2.5, 2.5, 0]
]
def unique_sorted(nums2: list[float | int]) -> list[float | int]:
    if len(nums2) == 0: 
        return 'ValueError'
    return sorted(set(nums2))
for i in test_u_s:
    print(unique_sorted(i))
```

### flatten
```python
fl_test = [
    [[1, 2], [3, 4]],
    ([1, 2], (3, 4, 5)),
    [[1], [], [2, 3]],
    [[1, 2], "ab"]
]
def flatten(mat: list[list | tuple]) -> list:
    result = []
    for a in mat:
        if isinstance(a, (list, tuple)): result.extend(flatten(a))
        else:
            if type(a) == int or type(a) == float: result.append(a)
            else: return 'TypeError'
    return result
for i in fl_test:
    print(flatten(i))
```
![–í—ã–≤–æ–¥:](./images/lab02/1x.png)

## –ó–∞–¥–∞–Ω–∏–µ 2 - matrix
### transpose
```python

test_t = [
    [[1, 2, 3]],
    [[1], [2], [3]],
    [[1, 2], [3, 4]],
    [],
    [[1, 2], [3]]
]


def transpose(mat: list[list[float | int]]) -> list[list]:
    if not mat:
        return []
    len_mat = len(mat[0])
    for i in mat:
        if len(i) != len_mat:
            return 'ValueError'

    len_column = len(mat[0]) 
    result_t = [[] for _ in range(len_column)]
    
    for str in range(len(mat)): 
        for column in range(len_column):  
            result_t[column].append(mat[str][column])  
    
    return result_t

for i in test_t:
    print(transpose(i))
```
### row_sums
```python
test_rs = [
    [[1, 2, 3], [4, 5, 6]],
    [[-1, 1], [10, -10]],
    [[0, 0], [0, 0]],
    [[1, 2], [3]]
]


def row_sums(mat: list[list[float | int]]) -> list[float]:
    res = []
    len_column = len(mat[0])
    for i in mat:
        if len(i) != len_column:
            return 'ValueError'
    for row in mat:
        row_sum = sum(row)
        res.append(row_sum)
    return res
for i in test_rs:
    print(row_sums(i))
```



### col_sums
```python
test_cs = [
    [[1, 2, 3], [4, 5, 6]],
    [[-1, 1], [10, -10]],
    [[0, 0], [0, 0]],
    [[1, 2], [3]]
]

def col_sums(mat: list[list[float | int]]) -> list[float]:
    result_cs = []
    len_str = len(mat[0])
    result_cs = [0] * len_str
    for i in mat:
        if len(i) != len_str:
            return 'ValueError'
        
    for column in mat:
        k = 0
        for strok in column:
            result_cs[k%len_str] = result_cs[k%len_str] + strok
            k+=1
    return result_cs
for i in test_cs:
    print(col_sums(i))
```

![–í—ã–≤–æ–¥:](./images/lab01/02r.png)

## –ó–∞–¥–∞–Ω–∏–µ 3 - tuples
```python
test_input = [
    ("–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á", "BIVT-25", 4.6),
    ("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä", "IKBO-12", 5.0),
    ("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä –ü–µ—Ç—Ä–æ–≤–∏—á", "IKBO-12", 5.0),
    ("  —Å–∏–¥–æ—Ä–æ–≤–∞  –∞–Ω–Ω–∞   —Å–µ—Ä–≥–µ–µ–≤–Ω–∞ ", "ABB-01", 3.999), 
    (' FJJ ', 'RR'),
    ('WER', 'Det', 52), 
    ('qw', '', 53.9)
]
def format_record(rec: tuple[str, str, float]) -> str: 
    if not isinstance(rec[2], float):
        return TypeError
    try: 
        len(rec)!= 3 or type(rec[0]) != str or type(rec[1]) != str or type(rec[2]) != float or len(rec[0])==0 or len(rec[1])==0 
    
        name, gr, gpa = rec
    
        name = name.split()
        if len(name) == 3: name = f'{name[0].title()} {name[1][0].upper()}.{name[1][0].upper()}.'
        else: name = f'{name[0].title()} {name[1][0].upper()}.'
        return f'{name}, –≥—Ä. {gr}, GPA {gpa}'
    except:
        return TypeError

for i in test_input:
    print(format_record(i))
```
![–í—ã–≤–æ–¥:](./images/lab02/3x.png)


# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 3
## text.py
* _—Ñ–∞–π–ª –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–π_
```python
import re  

def normalize(text: str, *, casefold: bool = True, replacement: bool = True) -> str:
    if not text:
        return ''
    
    
    if casefold:
        text = text.casefold()
    
    if replacement:
        text = text.replace('—ë', '–µ').replace('–Å', '–ï')
    
    text = text.replace('\t', ' ').replace('\r', ' ').replace('\n', ' ')
    
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text


def tokenize(text: str) -> list[str]:
    if not text:
        return []
    pattern = r'\w+(?:-\w+)*'
    tokens = re.findall(pattern, text)
    
    return tokens

def count_freq(tokens: list[str]) -> dict[str, int]:
    freq_dict = {}
    
    for token in tokens:
        freq_dict[token] = freq_dict.get(token, 0) + 1
    return freq_dict  

def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    items = list(freq.items())
    sorted_items = sorted(items, key=lambda x: (-x[1], x[0]))
    return sorted_items[:n]
```
## text_stats.py
* _—Ñ–∞–π–ª —Å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π —Ñ—É–Ω–∫—Ü–∏–π_
```python
iimport sys
import os

sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'lib'))
from text import normalize, tokenize, count_freq, top_n

sys.path.append(os.path.join(os.path.dirname(__file__)))
from test import normalize_test, tokenize_test, count_freq__top_n_test


for i in normalize_test:
    print(normalize(i))
for i in tokenize_test:
    print(tokenize(i))
for i in count_freq__top_n_test:
    print(count_freq(i))
    print(top_n(count_freq(i)))


def main():
    text = sys.stdin.readline().strip()  
    if not text:
        print("–í—Å–µ–≥–æ —Å–ª–æ–≤: 0")
        print("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: 0")
        print("–¢–æ–ø-5:")
        return
    
    normalized = normalize(text)
    tokens = tokenize(normalized)
    
    total = len(tokens)
    unique = len(set(tokens))
    freq_dict = count_freq(tokens)
    top_words = top_n(freq_dict, 5)
    
    print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {total}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {unique}")
    print(f"–¢–æ–ø-{min(5, len(set(tokens)))}:")
    for word, count in top_words:
        print(f"{word}:{count}")

if __name__ == "__main__":
    main()

```
### test.py
* _—Ñ–∞–π–ª —Å —Ç–µ—Å—Ç–∞–º–∏_
```python
normalize_test = [
    "–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t",
    "—ë–∂–∏–∫, –Å–ª–∫–∞",
    "Hello\r\nWorld",
    "  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  "
]


tokenize_test = [
    "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä",
    "hello,world!!!",
    "–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ",
    "2025 –≥–æ–¥",
    "emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ"
] 


count_freq__top_n_test = [
    ["a","b","a","c","b","a"],
    ["bb","aa","bb","aa","cc"]
]

```


#### –í—ã–≤–æ–¥:
![–í—ã–≤–æ–¥:](./images/lab03/img.png)

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 4


## —Ñ–∞–π–ª io_txt_cvs.py
```python
mport csv
from pathlib import Path #–¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø—É—Ç—è–º–∏ —Ñ–∞–π–ª–æ–≤
from typing import Iterable, Sequence

def read_text(path: str | Path, encoding: str = 'utf-8') -> str: #—á—Ç–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞
    path = Path(path)
    if path.suffix.lower() != '.txt':
        raise ValueError(f"—Ñ–∞–π–ª {path} –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ .txt")
    return path.read_text(encoding=encoding)

def write_csv(rows: Iterable[Sequence], path: str | Path, header: tuple[str, ...] | None = None) -> None:
    path = Path(path)
    if path.suffix.lower() != '.csv':
        raise ValueError(f"—Ñ–∞–π–ª {path} –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ .csv")
    rows = list(rows)
    if rows:
        first_len = len(rows[0])
        for i, roww in enumerate(rows): #–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω–¥–µ–∫—Å, —ç–ª–µ–º–µ–Ω—Ç
            if len(roww) != first_len:
                raise ValueError(f'–°—Ç—Ä–æ–∫–∞ {i} –∏–º–µ–µ—Ç –¥–ª–∏–Ω—É {len(roww)}, –æ–∂–∏–¥–∞–ª–æ—Å—å {first_len}') 
            
    with path.open('w', newline='', encoding='utf-8') as f: #–æ—Ç–∫—Ä—ã—Ç–∏–µ —Ñ–∞–π–ª–∞ –¥–ª—è –∑–∞–ø–∏—Å–∏ 
        w = csv.writer(f)
        if header is not None: #e—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω –∑–∞–≥–æ–ª–æ–≤–æ–∫
            w.writerow(header)
        for r in rows:
            w.writerow(r) # –ø–æ—Å—Ç—Ä–æ—á–Ω–æ –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –≤ csv


if __name__ == '__main__':
    print('—Ç–µ—Å—Ç')
    try:
        txt = read_text('data/lab04/input.txt')  # –¥–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å —Å—Ç—Ä–æ–∫—É
        print(f'–ü—Ä–æ—á–∏—Ç–∞–Ω–æ {len(txt)} —Å–∏–º–≤–æ–ª–æ–≤')
        print(f'–ü–µ—Ä–≤—ã–µ 50 —Å–∏–º–≤–æ–ª–æ–≤: {txt[:50]}')
    except FileNotFoundError:
        print('–§–∞–π–ª –Ω–µ –Ω–≤–π–¥–µ–Ω')
    except Exception as e:
        print('–æ—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {e}')
    
    try:
        write_csv([('word','count'),('test',3)], 'data/check.csv')  # —Å–æ–∑–¥–∞—Å—Ç CSV
    except Exception as e:
        print('–æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ CSV')
```


## —Ñ–∞–π–ª text_report.py
```python
import sys
from pathlib import Path
from collections import Counter 
sys.path.insert(0, str((Path(__file__).parent.parent))) #–¥–æ–±–∞–≤–ª—è—Ç –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ –Ω–∞—á–∞–ª–æ —Å–ø–∏—Å–∫–∞
from lib.text import normalize, tokenize, top_n
from lab04.io_txt_csv import read_text, write_csv
def frequencies_from_text(text: str) -> dict[str, int]: #–ø–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —á–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤
    tokens = tokenize(normalize(text))
    return Counter(tokens) 

def sorted_word_counts(freq: dict[str, int]) -> list[tuple[str, int]]: #—Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —É–±—ã–≤–∞–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã, –ø–æ –∞–≤—Ñ–∞–≤–∏—Ç—É
    return sorted(freq.items(), key=lambda kv: (-kv[1], kv[0]))
def report(input_path: Path, output_path: Path, encoding: str = 'utf-8') -> dict[str, int]: #–æ—á—Ç—ë—Ç
    try:
        if input_path.suffix.lower() != '.txt':
            raise ValueError(f"–≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å .txt, –ø–æ–ª—É—á–µ–Ω: {input_path.suffix}")
        
        if output_path.suffix.lower() != '.csv':
            raise ValueError(f"–≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å .csv, –ø–æ–ª—É—á–µ–Ω: {output_path.suffix}")
        text = read_text(input_path, encoding=encoding)
        if not text.strip():
            print('—Ñ–∞–π–ª –ø—É—Å—Ç–æ–π')
            header = ('word', 'count')
            write_csv([], output_path, header)  # –¢–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫
            return ''     
        freq = frequencies_from_text(text)
        sorted_counts = sorted_word_counts(freq)
        header = ('word', 'count') #–∑–∞–≥–æ–ª–æ–≤–æ–∫
        write_csv(sorted_counts, output_path, header)
        return freq
    except FileNotFoundError:
        print(f'FileNotFoundError')
        sys.exit(1) #–∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã —Å –æ—à–∏–±–∫–æ–π
        
    except Exception as e:
        print(f'–æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {e}')
        sys.exit(1)


def main():
    input_file = Path('data/lab04/input.txt')
    output_file = Path('data/lab04/report.csv') #–ø—É—Ç—å –¥–ª—è –≤—ã—Ö–æ–¥–∞
    print(f'...–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {input_file}')
    try:
        frequencies = report(input_file, output_file)
        sum_words = sum(frequencies.values()) #–∫–æ–ª-–≤–æ —Å–ª–æ–≤
        unique_words = len(frequencies) #–∫–æ–ª-–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤
        top_words = top_n(frequencies, 5)        
        print(f'–í—Å–µ–≥–æ —Å–ª–æ–≤: {sum_words}')
        print(f'–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {unique_words}')
        print('–¢–æ–ø-5:')

        for word, count in top_words:
            print(f'  {word}: {count}')
    except Exception as e:
        print(f'–æ—à–∏–±–∫–∞ {e}')

if __name__ == '__main__':
    main()
```


## –∑–∞–ø—É—Å–∫ '–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä! –ü—Ä–∏–≤–µ—Ç!!!':

![–í—ã–≤–æ–¥:](./images/lab04/1.png)


![–í—ã–≤–æ–¥:](./images/lab04/1x.png)


![–í—ã–≤–æ–¥:](./images/lab04/1xx.png)
## –∑–∞–ø—É—Å–∫ —Å –ø—É—Å—Ç—ã–º —Ñ–∞–π–ª–æ–º input.txt:

![–í—ã–≤–æ–¥:](./images/lab04/2.png)


![–í—ã–≤–æ–¥:](./images/lab04/2x.png)


![–í—ã–≤–æ–¥:](./images/lab04/2xx.png)

## –∑–∞–ø—É—Å–∫ —Å –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ–º —Ñ–∞–π–ª–∞ input.txt:

![–í—ã–≤–æ–¥:](./images/lab04/0.png)



# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 5

## —Ñ–∞–π–ª json_csv.py
```python
import json
import csv
from pathlib import Path
def json_to_csv(json_path: str, csv_path: str) -> None:
    json_file = Path(json_path)
    csv_file = Path(csv_path)
    if not json_file.exists(): # –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –∏—Å—Ö–æ–¥–Ω—ã–π JSON —Ñ–∞–π–ª
        raise FileNotFoundError(f'JSON —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {json_path}')
    data = None # —Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON
    
    try:
        with json_file.open('r', encoding='utf-8') as f: # —á—Ç–µ–Ω–∏–µ JSON —Ñ–∞–π–ª–∞
            data = json.load(f) # –∑–∞–≥—Ä—É–∂–∞–µ–º JSON –¥–∞–Ω–Ω—ã–µ
            
    except json.JSONDecodeError as e:
        raise ValueError(f'–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç JSON –≤ —Ñ–∞–π–ª–µ {json_path}: {str(e)}')
    except UnicodeDecodeError as e:
        raise ValueError(f'–ü—Ä–æ–±–ª–µ–º–∞ —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π —Ñ–∞–π–ª–∞ {json_path}: {str(e)}')
    
    # –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
    if not isinstance(data, list): # –ø—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ —è–≤–ª—è—é—Ç—Å—è —Å–ø–∏—Å–∫–æ–º
        raise ValueError(f'JSON –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤, –ø–æ–ª—É—á–µ–Ω {type(data).__name__}')
    if len(data) == 0:
        raise ValueError('–ü—É—Å—Ç–æ–π JSON —Ñ–∞–π–ª')
    
    for item in data: # –ø—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å–ø–∏—Å–∫–∞ —è–≤–ª—è—é—Ç—Å—è —Å–ª–æ–≤–∞—Ä—è–º–∏
        if not isinstance(item, dict):
            raise ValueError(f'—ç–ª–µ–º–µ–Ω—Ç/—ç–ª–µ–º–µ–Ω—Ç—ã –Ω–µ —è–≤–ª—è—é—Ç—Å—è —Å–ª–æ–≤–∞—Ä—è–º–∏')
    all_keys = set()
    for item in data:
        all_keys.update(item.keys()) # –¥–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –∫–ª—é—á–∏ —Ç–µ–∫—É—â–µ–≥–æ —Å–ª–æ–≤–∞—Ä—è –≤ –º–Ω–æ–∂–µ—Å—Ç–≤–æ
    
    if not all_keys: # –µ—Å–ª–∏ –≤—Å–µ —Å–ª–æ–≤–∞—Ä–∏ –ø—É—Å—Ç—ã–µ
        raise ValueError('JSON –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–∏–∫–∞–∫–∏—Ö –ø–æ–ª–µ–π (–≤—Å–µ —Å–ª–æ–≤–∞—Ä–∏ –ø—É—Å—Ç—ã–µ)')
    fieldnames = sorted(all_keys) 
    csv_file.parent.mkdir(parents=True, exist_ok=True) # —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è CSV —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    
    try:
        with csv_file.open('w', encoding='utf-8', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames) # –°–æ–∑–¥–∞–µ–º DictWriter —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏
            writer.writeheader()# –∑–∞–ø–∏—Å—å –∑–∞–≥–æ–ª–æ–≤–æ–∫–∞
            
            for item in data:
                row = {}
                for key in fieldnames:
                    row[key] = item.get(key, '')
                writer.writerow(row)
                
    except PermissionError as e:
        raise ValueError(f'–ù–µ—Ç –ø—Ä–∞–≤ –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤ —Ñ–∞–π–ª {csv_path}: {str(e)}')
    except Exception as e:
        raise ValueError(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ CSV —Ñ–∞–π–ª–∞: {str(e)}')

def csv_to_json(csv_path: str, json_path: str) -> None:
    csv_file = Path(csv_path)
    json_file = Path(json_path)
    
    try:
        with csv_file.open('r', encoding='utf-8', newline='') as f:  # –æ—Ç–∫—Ä—ã–≤–∞–µ–º CSV!
            sample = f.read(1024) # –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–∏–∞–ª–µ–∫—Ç–∞
            dialect = csv.Sniffer().sniff(sample)
            f.seek(0) # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ –Ω–∞—á–∞–ª—É –ø–æ—Å–ª–µ sniff
            data = list(csv.DictReader(f, dialect=dialect))

        if not csv.Sniffer().has_header(sample):
                raise ValueError('CSV —Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞')
            
    except FileNotFoundError:
        raise FileNotFoundError('—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω')
    except Exception as e:
        raise ValueError(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ CSV —Ñ–∞–π–ª–∞: {str(e)}')
    if len(data) == 0:
        raise ValueError('–ü—É—Å—Ç–æ–π JSON —Ñ–∞–π–ª')
    
    try:
        with json_file.open('w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
                
    except PermissionError as e:
        raise ValueError(f'–ù–µ—Ç –ø—Ä–∞–≤ –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤ —Ñ–∞–π–ª {csv_path}: {str(e)}')
    except Exception as e:
        raise ValueError(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ CSV —Ñ–∞–π–ª–∞: {str(e)}')

if __name__ == '__main__':
    try:
        json_to_csv(
            'data/samples/people.json', 
            'data/out/people_from_json.csv'
        )
        print('—Ç–µ—Å—Ç json -> csv')
        csv_to_json(
            'data/samples/people.csv',
            'data/out/people_from_csv.json'
        )
        print('—Ç–µ—Å—Ç csv -> json')
    except Exception as e:
        print(f'–û—à–∏–±–∫–∞: {e}')
```
### —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã: 

![–í—ã–≤–æ–¥:](./images/lab05/people_json.png)

## ‚Üì


![–í—ã–≤–æ–¥:](./images/lab05/people_from_json.png)
### _____________________________________________________

![–í—ã–≤–æ–¥:](./images/lab05/people_csv.png)

## ‚Üì

![–í—ã–≤–æ–¥:](./images/lab05/people_from_csv.png)



## —Ñ–∞–π–ª csv_xlsx.py
```python
from openpyxl import Workbook
from openpyxl.utils import get_column_letter
import csv
from pathlib import Path


def column_width(worksheet): # –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —à–∏—Ä–∏–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫
    for column in worksheet.columns:
        max_length = 0
        column_letter = get_column_letter(column[0].column)
        
        # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É —Ç–µ–∫—Å—Ç–∞ –≤ –∫–æ–ª–æ–Ω–∫–µ
        for cell in column:
            try:
                if cell.value is not None:
                    cell_length = len(str(cell.value))
                    if cell_length > max_length:
                        max_length = cell_length
            except:
                pass
        adjusted_width = max(max_length + 2, 8)  
        worksheet.column_dimensions[column_letter].width = adjusted_width



def csv_to_xlsx(csv_path: str, xlsx_path: str) -> None:
    csv_file = Path(csv_path)
    if not csv_file.exists():
        raise FileNotFoundError(f'CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {csv_path}')
    wb = Workbook()
    ws = wb.active
    ws.title = 'Sheet1' 
    try:
        with csv_file.open('r', encoding='utf-8', newline='') as f:
            csv_reader = csv.reader(f)

            for row_idx, row in enumerate(csv_reader, 1):
                for col_idx, value in enumerate(row, 1):
                    ws.cell(row=row_idx, column=col_idx, value=value)
        column_width(ws)
        xlsx_file = Path(xlsx_path)
        xlsx_file.parent.mkdir(parents=True, exist_ok=True)
        wb.save(xlsx_path)
        print(f'–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ CSV ‚Üí XLSX: {csv_path} ‚Üí {xlsx_path}')
        print(f'—Ä–∞–∑–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã: {ws.max_row} √ó {ws.max_column}')
        
    except Exception as e:
        raise ValueError(f'–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ CSV -> XLSX: {str(e)}')

# –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é
if __name__ == '__main__':
    try:
        csv_to_xlsx(
            'data/samples/people.csv',
            'data/out/people.xlsx'
        )
        print('–¢–µ—Å—Ç CSV ‚Üí XLSX')
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ç–µ—Å—Ç —Å cities.csv
        csv_to_xlsx(
            'data/samples/cities.csv',
            'data/out/cities.xlsx'
        )
        print('–¢–µ—Å—Ç cities.csv ‚Üí XLSX')
        
    except Exception as e:
        print(f'–û—à–∏–±–∫–∞: {e}')
```

### —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã: 

![–í—ã–≤–æ–¥:](./images/lab05/people_csv.png)

##                                              ‚Üì


![–í—ã–≤–æ–¥:](./images/lab05/name_xl.png)

### _____________________________________________________
![–í—ã–≤–æ–¥:](./images/lab05/cities_csv.png)

##                                              ‚Üì


![–í—ã–≤–æ–¥:](./images/lab05/cities_xl.png)