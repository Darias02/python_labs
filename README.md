# python_labs
# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 1
## –ó–∞–¥–∞–Ω–∏–µ 1
![–ö–æ–¥:](./images/lab01/01.png)
![–í—ã–≤–æ–¥:](./images/lab01/01r.png)

## –ó–∞–¥–∞–Ω–∏–µ 2
![–ö–æ–¥:](./images/lab01/02.png)
![–í—ã–≤–æ–¥:](./images/lab01/02r.png)

## –ó–∞–¥–∞–Ω–∏–µ 3
![–ö–æ–¥:](./images/lab01/03.png)
![–í—ã–≤–æ–¥:](./images/lab01/03r.png)

## –ó–∞–¥–∞–Ω–∏–µ 4
![–ö–æ–¥:](./images/lab01/04.png)
![–í—ã–≤–æ–¥:](./images/lab01/04r.png)

## –ó–∞–¥–∞–Ω–∏–µ 5
![–ö–æ–¥:](./images/lab01/05.png)
![–í—ã–≤–æ–¥:](./images/lab01/05r.png)

## –ó–∞–¥–∞–Ω–∏–µ 6
![–ö–æ–¥:](./images/lab01/06.png)
![–í—ã–≤–æ–¥:](./images/lab01/06r.png)

## –ó–∞–¥–∞–Ω–∏–µ 7
![–ö–æ–¥:](images/lab01/07.png)
![–í—ã–≤–æ–¥:](./images/lab01/07r.png)

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 2

## –ó–∞–¥–∞–Ω–∏–µ 1 - arrays
### min_max
```python
test_m_m = [
    [3, -1, 5, 5, 0],
    [42],
    [-5, -2, -9],
    [],
    [1.5, 2, 2.0, -3.1]
]
def min_max(nums: list[float | int]) -> tuple[float | int, float | int]:
    if len(nums) == 0: 
        return 'ValueError'
    return (min(nums), max(nums)) 
for i in test_m_m:
    print(min_max(i))
```
### unique_sorted
```python
test_u_s = [
    [3, 1, 2, 1, 3],
    [],
    [-1, -1, 0, 2, 2],
    [1.0, 1, 2.5, 2.5, 0]
]
def unique_sorted(nums2: list[float | int]) -> list[float | int]:
    if len(nums2) == 0: 
        return 'ValueError'
    return sorted(set(nums2))
for i in test_u_s:
    print(unique_sorted(i))
```

### flatten
```python
fl_test = [
    [[1, 2], [3, 4]],
    ([1, 2], (3, 4, 5)),
    [[1], [], [2, 3]],
    [[1, 2], "ab"]
]
def flatten(mat: list[list | tuple]) -> list:
    result = []
    for a in mat:
        if isinstance(a, (list, tuple)): result.extend(flatten(a))
        else:
            if type(a) == int or type(a) == float: result.append(a)
            else: return 'TypeError'
    return result
for i in fl_test:
    print(flatten(i))
```
![–í—ã–≤–æ–¥:](./images/lab02/1x.png)

## –ó–∞–¥–∞–Ω–∏–µ 2 - matrix
### transpose
```python

test_t = [
    [[1, 2, 3]],
    [[1], [2], [3]],
    [[1, 2], [3, 4]],
    [],
    [[1, 2], [3]]
]


def transpose(mat: list[list[float | int]]) -> list[list]:
    if not mat:
        return []
    len_mat = len(mat[0])
    for i in mat:
        if len(i) != len_mat:
            return 'ValueError'

    len_column = len(mat[0]) 
    result_t = [[] for _ in range(len_column)]
    
    for str in range(len(mat)): 
        for column in range(len_column):  
            result_t[column].append(mat[str][column])  
    
    return result_t

for i in test_t:
    print(transpose(i))
```
### row_sums
```python
test_rs = [
    [[1, 2, 3], [4, 5, 6]],
    [[-1, 1], [10, -10]],
    [[0, 0], [0, 0]],
    [[1, 2], [3]]
]


def row_sums(mat: list[list[float | int]]) -> list[float]:
    res = []
    len_column = len(mat[0])
    for i in mat:
        if len(i) != len_column:
            return 'ValueError'
    for row in mat:
        row_sum = sum(row)
        res.append(row_sum)
    return res
for i in test_rs:
    print(row_sums(i))
```



### col_sums
```python
test_cs = [
    [[1, 2, 3], [4, 5, 6]],
    [[-1, 1], [10, -10]],
    [[0, 0], [0, 0]],
    [[1, 2], [3]]
]

def col_sums(mat: list[list[float | int]]) -> list[float]:
    result_cs = []
    len_str = len(mat[0])
    result_cs = [0] * len_str
    for i in mat:
        if len(i) != len_str:
            return 'ValueError'
        
    for column in mat:
        k = 0
        for strok in column:
            result_cs[k%len_str] = result_cs[k%len_str] + strok
            k+=1
    return result_cs
for i in test_cs:
    print(col_sums(i))
```

![–í—ã–≤–æ–¥:](./images/lab01/02r.png)

## –ó–∞–¥–∞–Ω–∏–µ 3 - tuples
```python
test_input = [
    ("–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á", "BIVT-25", 4.6),
    ("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä", "IKBO-12", 5.0),
    ("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä –ü–µ—Ç—Ä–æ–≤–∏—á", "IKBO-12", 5.0),
    ("  —Å–∏–¥–æ—Ä–æ–≤–∞  –∞–Ω–Ω–∞   —Å–µ—Ä–≥–µ–µ–≤–Ω–∞ ", "ABB-01", 3.999), 
    (' FJJ ', 'RR'),
    ('WER', 'Det', 52), 
    ('qw', '', 53.9)
]
def format_record(rec: tuple[str, str, float]) -> str: 
    if not isinstance(rec[2], float):
        return TypeError
    try: 
        len(rec)!= 3 or type(rec[0]) != str or type(rec[1]) != str or type(rec[2]) != float or len(rec[0])==0 or len(rec[1])==0 
    
        name, gr, gpa = rec
    
        name = name.split()
        if len(name) == 3: name = f'{name[0].title()} {name[1][0].upper()}.{name[1][0].upper()}.'
        else: name = f'{name[0].title()} {name[1][0].upper()}.'
        return f'{name}, –≥—Ä. {gr}, GPA {gpa}'
    except:
        return TypeError

for i in test_input:
    print(format_record(i))
```
![–í—ã–≤–æ–¥:](./images/lab02/3x.png)


# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 3
## text.py
* _—Ñ–∞–π–ª –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–π_
```python
import re  

def normalize(text: str, *, casefold: bool = True, replacement: bool = True) -> str:
    if not text:
        return ''
    
    
    if casefold:
        text = text.casefold()
    
    if replacement:
        text = text.replace('—ë', '–µ').replace('–Å', '–ï')
    
    text = text.replace('\t', ' ').replace('\r', ' ').replace('\n', ' ')
    
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text


def tokenize(text: str) -> list[str]:
    if not text:
        return []
    pattern = r'\w+(?:-\w+)*'
    tokens = re.findall(pattern, text)
    
    return tokens

def count_freq(tokens: list[str]) -> dict[str, int]:
    freq_dict = {}
    
    for token in tokens:
        freq_dict[token] = freq_dict.get(token, 0) + 1
    return freq_dict  

def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    items = list(freq.items())
    sorted_items = sorted(items, key=lambda x: (-x[1], x[0]))
    return sorted_items[:n]
```
## text_stats.py
* _—Ñ–∞–π–ª —Å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π —Ñ—É–Ω–∫—Ü–∏–π_
```python
iimport sys
import os

sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'lib'))
from text import normalize, tokenize, count_freq, top_n

sys.path.append(os.path.join(os.path.dirname(__file__)))
from test import normalize_test, tokenize_test, count_freq__top_n_test


for i in normalize_test:
    print(normalize(i))
for i in tokenize_test:
    print(tokenize(i))
for i in count_freq__top_n_test:
    print(count_freq(i))
    print(top_n(count_freq(i)))


def main():
    text = sys.stdin.readline().strip()  
    if not text:
        print("–í—Å–µ–≥–æ —Å–ª–æ–≤: 0")
        print("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: 0")
        print("–¢–æ–ø-5:")
        return
    
    normalized = normalize(text)
    tokens = tokenize(normalized)
    
    total = len(tokens)
    unique = len(set(tokens))
    freq_dict = count_freq(tokens)
    top_words = top_n(freq_dict, 5)
    
    print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {total}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {unique}")
    print(f"–¢–æ–ø-{min(5, len(set(tokens)))}:")
    for word, count in top_words:
        print(f"{word}:{count}")

if __name__ == "__main__":
    main()

```
### test.py
* _—Ñ–∞–π–ª —Å —Ç–µ—Å—Ç–∞–º–∏_
```python
normalize_test = [
    "–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t",
    "—ë–∂–∏–∫, –Å–ª–∫–∞",
    "Hello\r\nWorld",
    "  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  "
]


tokenize_test = [
    "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä",
    "hello,world!!!",
    "–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ",
    "2025 –≥–æ–¥",
    "emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ"
] 


count_freq__top_n_test = [
    ["a","b","a","c","b","a"],
    ["bb","aa","bb","aa","cc"]
]

```


#### –í—ã–≤–æ–¥:
![–í—ã–≤–æ–¥:](./images/lab03/img.png)

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 4


## —Ñ–∞–π–ª io_txt_cvs.py
```python
mport csv
from pathlib import Path #–¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø—É—Ç—è–º–∏ —Ñ–∞–π–ª–æ–≤
from typing import Iterable, Sequence

def read_text(path: str | Path, encoding: str = 'utf-8') -> str: #—á—Ç–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞
    path = Path(path)
    if path.suffix.lower() != '.txt':
        raise ValueError(f"—Ñ–∞–π–ª {path} –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ .txt")
    return path.read_text(encoding=encoding)

def write_csv(rows: Iterable[Sequence], path: str | Path, header: tuple[str, ...] | None = None) -> None:
    path = Path(path)
    if path.suffix.lower() != '.csv':
        raise ValueError(f"—Ñ–∞–π–ª {path} –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ .csv")
    rows = list(rows)
    if rows:
        first_len = len(rows[0])
        for i, roww in enumerate(rows): #–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω–¥–µ–∫—Å, —ç–ª–µ–º–µ–Ω—Ç
            if len(roww) != first_len:
                raise ValueError(f'–°—Ç—Ä–æ–∫–∞ {i} –∏–º–µ–µ—Ç –¥–ª–∏–Ω—É {len(roww)}, –æ–∂–∏–¥–∞–ª–æ—Å—å {first_len}') 
            
    with path.open('w', newline='', encoding='utf-8') as f: #–æ—Ç–∫—Ä—ã—Ç–∏–µ —Ñ–∞–π–ª–∞ –¥–ª—è –∑–∞–ø–∏—Å–∏ 
        w = csv.writer(f)
        if header is not None: #e—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω –∑–∞–≥–æ–ª–æ–≤–æ–∫
            w.writerow(header)
        for r in rows:
            w.writerow(r) # –ø–æ—Å—Ç—Ä–æ—á–Ω–æ –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –≤ csv


if __name__ == '__main__':
    print('—Ç–µ—Å—Ç')
    try:
        txt = read_text('data/lab04/input.txt')  # –¥–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å —Å—Ç—Ä–æ–∫—É
        print(f'–ü—Ä–æ—á–∏—Ç–∞–Ω–æ {len(txt)} —Å–∏–º–≤–æ–ª–æ–≤')
        print(f'–ü–µ—Ä–≤—ã–µ 50 —Å–∏–º–≤–æ–ª–æ–≤: {txt[:50]}')
    except FileNotFoundError:
        print('–§–∞–π–ª –Ω–µ –Ω–≤–π–¥–µ–Ω')
    except Exception as e:
        print('–æ—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {e}')
    
    try:
        write_csv([('word','count'),('test',3)], 'data/check.csv')  # —Å–æ–∑–¥–∞—Å—Ç CSV
    except Exception as e:
        print('–æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ CSV')
```


## —Ñ–∞–π–ª text_report.py
```python
import sys
from pathlib import Path
from collections import Counter 
sys.path.insert(0, str((Path(__file__).parent.parent))) #–¥–æ–±–∞–≤–ª—è—Ç –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ –Ω–∞—á–∞–ª–æ —Å–ø–∏—Å–∫–∞
from lib.text import normalize, tokenize, top_n
from lab04.io_txt_csv import read_text, write_csv
def frequencies_from_text(text: str) -> dict[str, int]: #–ø–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —á–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤
    tokens = tokenize(normalize(text))
    return Counter(tokens) 

def sorted_word_counts(freq: dict[str, int]) -> list[tuple[str, int]]: #—Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —É–±—ã–≤–∞–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã, –ø–æ –∞–≤—Ñ–∞–≤–∏—Ç—É
    return sorted(freq.items(), key=lambda kv: (-kv[1], kv[0]))
def report(input_path: Path, output_path: Path, encoding: str = 'utf-8') -> dict[str, int]: #–æ—á—Ç—ë—Ç
    try:
        if input_path.suffix.lower() != '.txt':
            raise ValueError(f"–≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å .txt, –ø–æ–ª—É—á–µ–Ω: {input_path.suffix}")
        
        if output_path.suffix.lower() != '.csv':
            raise ValueError(f"–≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å .csv, –ø–æ–ª—É—á–µ–Ω: {output_path.suffix}")
        text = read_text(input_path, encoding=encoding)
        if not text.strip():
            print('—Ñ–∞–π–ª –ø—É—Å—Ç–æ–π')
            header = ('word', 'count')
            write_csv([], output_path, header)  # –¢–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫
            return ''     
        freq = frequencies_from_text(text)
        sorted_counts = sorted_word_counts(freq)
        header = ('word', 'count') #–∑–∞–≥–æ–ª–æ–≤–æ–∫
        write_csv(sorted_counts, output_path, header)
        return freq
    except FileNotFoundError:
        print(f'FileNotFoundError')
        sys.exit(1) #–∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã —Å –æ—à–∏–±–∫–æ–π
        
    except Exception as e:
        print(f'–æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {e}')
        sys.exit(1)


def main():
    input_file = Path('data/lab04/input.txt')
    output_file = Path('data/lab04/report.csv') #–ø—É—Ç—å –¥–ª—è –≤—ã—Ö–æ–¥–∞
    print(f'...–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {input_file}')
    try:
        frequencies = report(input_file, output_file)
        sum_words = sum(frequencies.values()) #–∫–æ–ª-–≤–æ —Å–ª–æ–≤
        unique_words = len(frequencies) #–∫–æ–ª-–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤
        top_words = top_n(frequencies, 5)        
        print(f'–í—Å–µ–≥–æ —Å–ª–æ–≤: {sum_words}')
        print(f'–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {unique_words}')
        print('–¢–æ–ø-5:')

        for word, count in top_words:
            print(f'  {word}: {count}')
    except Exception as e:
        print(f'–æ—à–∏–±–∫–∞ {e}')

if __name__ == '__main__':
    main()
```


## –∑–∞–ø—É—Å–∫ '–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä! –ü—Ä–∏–≤–µ—Ç!!!':

![–í—ã–≤–æ–¥:](./images/lab04/1.png)


![–í—ã–≤–æ–¥:](./images/lab04/1x.png)


![–í—ã–≤–æ–¥:](./images/lab04/1xx.png)
## –∑–∞–ø—É—Å–∫ —Å –ø—É—Å—Ç—ã–º —Ñ–∞–π–ª–æ–º input.txt:

![–í—ã–≤–æ–¥:](./images/lab04/2.png)


![–í—ã–≤–æ–¥:](./images/lab04/2x.png)


![–í—ã–≤–æ–¥:](./images/lab04/2xx.png)

## –∑–∞–ø—É—Å–∫ —Å –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ–º —Ñ–∞–π–ª–∞ input.txt:

![–í—ã–≤–æ–¥:](./images/lab04/0.png)



# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 5

## —Ñ–∞–π–ª json_csv.py
```python
import json
import csv
from pathlib import Path
def json_to_csv(json_path: str, csv_path: str) -> None:
    json_file = Path(json_path)
    csv_file = Path(csv_path)
    if not json_file.exists(): # –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –∏—Å—Ö–æ–¥–Ω—ã–π JSON —Ñ–∞–π–ª
        raise FileNotFoundError(f'JSON —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {json_path}')
    data = None # —Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON
    
    try:
        with json_file.open('r', encoding='utf-8') as f: # —á—Ç–µ–Ω–∏–µ JSON —Ñ–∞–π–ª–∞
            data = json.load(f) # –∑–∞–≥—Ä—É–∂–∞–µ–º JSON –¥–∞–Ω–Ω—ã–µ
            
    except json.JSONDecodeError as e:
        raise ValueError(f'–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç JSON –≤ —Ñ–∞–π–ª–µ {json_path}: {str(e)}')
    except UnicodeDecodeError as e:
        raise ValueError(f'–ü—Ä–æ–±–ª–µ–º–∞ —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π —Ñ–∞–π–ª–∞ {json_path}: {str(e)}')
    
    # –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
    if not isinstance(data, list): # –ø—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ —è–≤–ª—è—é—Ç—Å—è —Å–ø–∏—Å–∫–æ–º
        raise ValueError(f'JSON –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤, –ø–æ–ª—É—á–µ–Ω {type(data).__name__}')
    if len(data) == 0:
        raise ValueError('–ü—É—Å—Ç–æ–π JSON —Ñ–∞–π–ª')
    
    for item in data: # –ø—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å–ø–∏—Å–∫–∞ —è–≤–ª—è—é—Ç—Å—è —Å–ª–æ–≤–∞—Ä—è–º–∏
        if not isinstance(item, dict):
            raise ValueError(f'—ç–ª–µ–º–µ–Ω—Ç/—ç–ª–µ–º–µ–Ω—Ç—ã –Ω–µ —è–≤–ª—è—é—Ç—Å—è —Å–ª–æ–≤–∞—Ä—è–º–∏')
    all_keys = set()
    for item in data:
        all_keys.update(item.keys()) # –¥–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –∫–ª—é—á–∏ —Ç–µ–∫—É—â–µ–≥–æ —Å–ª–æ–≤–∞—Ä—è –≤ –º–Ω–æ–∂–µ—Å—Ç–≤–æ
    
    if not all_keys: # –µ—Å–ª–∏ –≤—Å–µ —Å–ª–æ–≤–∞—Ä–∏ –ø—É—Å—Ç—ã–µ
        raise ValueError('JSON –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–∏–∫–∞–∫–∏—Ö –ø–æ–ª–µ–π (–≤—Å–µ —Å–ª–æ–≤–∞—Ä–∏ –ø—É—Å—Ç—ã–µ)')
    fieldnames = sorted(all_keys) 
    csv_file.parent.mkdir(parents=True, exist_ok=True) # —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è CSV —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    
    try:
        with csv_file.open('w', encoding='utf-8', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames) # –°–æ–∑–¥–∞–Ω–∏–µ DictWriter —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏
            writer.writeheader()# –∑–∞–ø–∏—Å—å –∑–∞–≥–æ–ª–æ–≤–æ–∫–∞
            
            for item in data:
                row = {}
                for key in fieldnames:
                    row[key] = item.get(key, '')
                writer.writerow(row)
                
    except PermissionError as e:
        raise ValueError(f'–ù–µ—Ç –ø—Ä–∞–≤ –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤ —Ñ–∞–π–ª {csv_path}: {str(e)}')
    except Exception as e:
        raise ValueError(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ CSV —Ñ–∞–π–ª–∞: {str(e)}')

def csv_to_json(csv_path: str, json_path: str) -> None:
    csv_file = Path(csv_path)
    json_file = Path(json_path)
    
    try:
        with csv_file.open('r', encoding='utf-8', newline='') as f: 
            sample = f.read(1024) # –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–∏–∞–ª–µ–∫—Ç–∞
            dialect = csv.Sniffer().sniff(sample)
            f.seek(0) # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ –Ω–∞—á–∞–ª—É –ø–æ—Å–ª–µ sniff
            data = list(csv.DictReader(f, dialect=dialect))

        if not csv.Sniffer().has_header(sample):
                raise ValueError('CSV —Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞')
            
    except FileNotFoundError:
        raise FileNotFoundError('—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω')
    except Exception as e:
        raise ValueError(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ CSV —Ñ–∞–π–ª–∞: {str(e)}')
    if len(data) == 0:
        raise ValueError('–ü—É—Å—Ç–æ–π JSON —Ñ–∞–π–ª')
    
    try:
        with json_file.open('w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
                
    except PermissionError as e:
        raise ValueError(f'–ù–µ—Ç –ø—Ä–∞–≤ –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤ —Ñ–∞–π–ª {csv_path}: {str(e)}')
    except Exception as e:
        raise ValueError(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ CSV —Ñ–∞–π–ª–∞: {str(e)}')

if __name__ == '__main__':
    try:
        json_to_csv(
            'data/samples/people.json', 
            'data/out/people_from_json.csv'
        )
        print('—Ç–µ—Å—Ç json -> csv')
        csv_to_json(
            'data/samples/people.csv',
            'data/out/people_from_csv.json'
        )
        print('—Ç–µ—Å—Ç csv -> json')
    except Exception as e:
        print(f'–û—à–∏–±–∫–∞: {e}')
```
### —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã: 

![–í—ã–≤–æ–¥:](./images/lab05/people_json.png)

## ‚Üì


![–í—ã–≤–æ–¥:](./images/lab05/people_from_json.png)
### _____________________________________________________

![–í—ã–≤–æ–¥:](./images/lab05/people_csv.png)

## ‚Üì

![–í—ã–≤–æ–¥:](./images/lab05/people_from_csv.png)



## —Ñ–∞–π–ª csv_xlsx.py
```python
from openpyxl import Workbook
from openpyxl.utils import get_column_letter
import csv
from pathlib import Path


def column_width(worksheet): # –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —à–∏—Ä–∏–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫
    for column in worksheet.columns:
        max_length = 0
        column_letter = get_column_letter(column[0].column)
        
        #–º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ –≤ –∫–æ–ª–æ–Ω–∫–µ
        for cell in column:
            try:
                if cell.value is not None:
                    cell_length = len(str(cell.value))
                    if cell_length > max_length:
                        max_length = cell_length
            except:
                pass
        adjusted_width = max(max_length + 2, 8)  
        worksheet.column_dimensions[column_letter].width = adjusted_width



def csv_to_xlsx(csv_path: str, xlsx_path: str) -> None:
    csv_file = Path(csv_path)
    if not csv_file.exists():
        raise FileNotFoundError(f'CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {csv_path}')
    if csv_file.suffix.lower() != '.csv':
        raise ValueError(f'–§–∞–π–ª {csv_file} –Ω–µ csv')
    xlsx_file = Path(xlsx_path)
    if xlsx_file.suffix.lower() != '.xlsx':
        raise ValueError(f'–§–∞–π–ª {xlsx_file} –Ω–µ xlsx')
    wb = Workbook()
    ws = wb.active
    ws.title = 'Sheet1' 
    try:
        with csv_file.open('r', encoding='utf-8', newline='') as f:
            csv_reader = csv.reader(f)

            for row_idx, row in enumerate(csv_reader, 1):
                for col_idx, value in enumerate(row, 1):
                    ws.cell(row=row_idx, column=col_idx, value=value)
        column_width(ws)
        xlsx_file = Path(xlsx_path)
        xlsx_file.parent.mkdir(parents=True, exist_ok=True)
        wb.save(xlsx_path)
        print(f'–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ CSV ‚Üí XLSX: {csv_path} ‚Üí {xlsx_path}')
        print(f'—Ä–∞–∑–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã: {ws.max_row} √ó {ws.max_column}')
        
    except Exception as e:
        raise ValueError(f'–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ CSV -> XLSX: {str(e)}')
    

if __name__ == '__main__':
    try:
        csv_to_xlsx(
            'data/samples/people.csv',
            'data/out/people.xlsx'
        )
        print('–¢–µ—Å—Ç CSV ‚Üí XLSX')
        
        csv_to_xlsx(
            'data/samples/cities.csv',
            'data/out/cities.xlsx'
        )
        print('–¢–µ—Å—Ç cities.csv ‚Üí XLSX')
        
    except Exception as e:
        print(f'–æ—à–∏–±–∫–∞: {e}')
```

### —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã: 

![–í—ã–≤–æ–¥:](./images/lab05/people_csv.png)

##                                              ‚Üì


![–í—ã–≤–æ–¥:](./images/lab05/name_xl.png)

### _____________________________________________________
![–í—ã–≤–æ–¥:](./images/lab05/cities_csv.png)

##                                              ‚Üì


![–í—ã–≤–æ–¥:](./images/lab05/cities_xl.png)



# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 6
## —Ñ–∞–π–ª cli_text.py
```python
import argparse
import sys
from pathlib import Path


from src.lib.text import normalize, tokenize, count_freq, top_n


# –∫–æ–º–∞–Ω–¥–∞ cat
def cmd_cat(path: Path, number: bool):
    if not path.exists():
        raise FileNotFoundError(f"—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")

    with path.open("r", encoding="utf-8") as f:
        for i, line in enumerate(f, start=1):
            line = line.rstrip("\n")
            if number:
                print(f"{i} {line}")
            else:
                print(line)


# –∫–æ–º–∞–Ω–¥–∞ stats
def cmd_stats(path: Path, top: int):
    if not path.exists():
        raise FileNotFoundError(f"—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")

    text = path.read_text(encoding="utf-8")
    normalized = normalize(text)  # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç
    tokens = tokenize(normalized)  # —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞
    freq = count_freq(tokens)  # —Å—á–∏—Ç–∞–µ–º —á–∞—Å—Ç–æ—Ç—ã
    top_words = top_n(freq, top)  # –±–µ—Ä—ë–º —Ç–æ–ø-n —Å–ª–æ–≤

    # –≤—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"–≤—Å–µ–≥–æ —Å–ª–æ–≤: {len(tokens)}")
    print(f"—É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(set(tokens))}")
    print(f"—Ç–æ–ø-{top}:")
    for word, count in top_words:
        print(f"{word}:{count}")


# —Å–æ–∑–¥–∞—ë–º –ø–∞—Ä—Å–µ—Ä –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
def build_parser():
    parser = argparse.ArgumentParser(description="cli –¥–ª—è cat –∏ stats")
    sub = parser.add_subparsers(dest="cmd")

    # –ø–æ–¥–∫–æ–º–∞–Ω–¥–∞ cat
    p_cat = sub.add_parser("cat", help="–≤—ã–≤–µ—Å—Ç–∏ —Ñ–∞–π–ª –ø–æ—Å—Ç—Ä–æ—á–Ω–æ")
    p_cat.add_argument("--input", required=True)
    p_cat.add_argument("-n", action="store_true", help="–Ω—É–º–µ—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫–∏")

    # –ø–æ–¥–∫–æ–º–∞–Ω–¥–∞ stats
    p_st = sub.add_parser("stats", help="–∞–Ω–∞–ª–∏–∑ —á–∞—Å—Ç–æ—Ç —Å–ª–æ–≤")
    p_st.add_argument("--input", required=True)
    p_st.add_argument("--top", type=int, default=5)

    return parser


# main - —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞
def main(argv=None):
    argv = argv or sys.argv[1:]
    parser = build_parser()
    args = parser.parse_args(argv)

    try:
        if args.cmd == "cat":
            cmd_cat(Path(args.input), args.n)
        elif args.cmd == "stats":
            cmd_stats(Path(args.input), args.top)
        else:
            parser.print_help()
    except FileNotFoundError as e:
        parser.error(str(e))


if __name__ == "__main__":
    main()
```
## —Ñ–∞–π–ª cli_convert.py
``` python
import argparse
import sys
from pathlib import Path

# –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ lab05 –Ω–∞–ø—Ä—è–º—É—é
from src.lab05.json_csv import json_to_csv, csv_to_json
from src.lab05.csv_xlsx import csv_to_xlsx


# —Å–æ–∑–¥–∞—ë–º –ø–∞—Ä—Å–µ—Ä –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
def build_parser():
    parser = argparse.ArgumentParser(description="–∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä—ã —Ñ–æ—Ä–º–∞—Ç–æ–≤")
    sub = parser.add_subparsers(dest="cmd")

    # json -> csv
    p1 = sub.add_parser("json2csv", help="–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å json->csv")
    p1.add_argument("--in", dest="input", required=True, help="–≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª (json)")
    p1.add_argument("--out", dest="output", required=True, help="–≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª (csv)")

    # csv -> json
    p2 = sub.add_parser("csv2json", help="–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å csv->json")
    p2.add_argument("--in", dest="input", required=True, help="–≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª (csv)")
    p2.add_argument("--out", dest="output", required=True, help="–≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª (json)")

    # csv -> xlsx
    p3 = sub.add_parser("csv2xlsx", help="–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å csv->xlsx")
    p3.add_argument("--in", dest="input", required=True, help="–≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª (csv)")
    p3.add_argument("--out", dest="output", required=True, help="–≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª (xlsx)")

    return parser


def main(argv=None):
    argv = argv or sys.argv[1:]
    parser = build_parser()
    args = parser.parse_args(argv)

    try:
        if args.cmd == "json2csv":
            json_to_csv(args.input, args.output)
            print(f"{args.input} -> {args.output}")
        elif args.cmd == "csv2json":
            csv_to_json(args.input, args.output)
            print(f"{args.input} -> {args.output}")
        elif args.cmd == "csv2xlsx":
            csv_to_xlsx(args.input, args.output)
            print(f"{args.input} -> {args.output}")
        else:
            parser.print_help()
    except FileNotFoundError as e:
        parser.error(str(e))
    except Exception as e:
        parser.error(f"–æ—à–∏–±–∫–∞: {e}")


if __name__ == "__main__":
    main()
```
### —Ç–µ—Ä–º–∏–Ω–∞–ª:
![–í—ã–≤–æ–¥:](./images/lab06/cat.png)

![–í—ã–≤–æ–¥:](./images/lab06/stats.png)

![–í—ã–≤–æ–¥:](./images/lab06/csv2json.png)

![–í—ã–≤–æ–¥:](./images/lab06/csv2xlsx.png)

![–í—ã–≤–æ–¥:](./images/lab06/json2csv.png)

![–í—ã–≤–æ–¥:](./images/lab06/help.png)



# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 7
## —Ñ–∞–π–ª test_text.py
```python
import pytest
from src.lib.text import normalize, tokenize, count_freq, top_n


@pytest.mark.parametrize(
    "source, expected",
    [
        ("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t", "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"),
        ("—ë–∂–∏–∫, –Å–ª–∫–∞", "–µ–∂–∏–∫, –µ–ª–∫–∞"),
        ("Hello\r\nWorld", "hello world"),
        ("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ", "–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"),
        ("", ""),
        ("\t\n\r  ", ""),
    ],
)
def test_normalize_basic(source, expected):
    assert normalize(source) == expected


@pytest.mark.parametrize(
    "source, expected",
    [
        ("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä", ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]),
        ("hello,world!!!", ["hello", "world"]),
        ("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ", ["–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É", "–∫—Ä—É—Ç–æ"]),
        ("2025 –≥–æ–¥", ["2025", "–≥–æ–¥"]),
        ("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ", ["emoji", "–Ω–µ", "—Å–ª–æ–≤–æ"]),
        ("", []),
        ("   ", []),
        ("!!! ???", []),
    ],
)
def test_tokenize_basic(source, expected):
    assert tokenize(source) == expected


@pytest.mark.parametrize(
    "source, expected",
    [
        (["a", "b", "a", "c", "b", "a"], {"a": 3, "b": 2, "c": 1}),
        (["bb", "aa", "bb", "aa", "cc"], {"bb": 2, "aa": 2, "cc": 1}),
        ([], {}),
        (["same", "same", "same"], {"same": 3}),
    ],
)
def test_count_freq(source, expected):
    assert count_freq(source) == expected


@pytest.mark.parametrize(
    "source, expected",
    [
        ({"a": 3, "b": 2, "c": 1}, [("a", 3), ("b", 2), ("c", 1)]),
        ({"bb": 2, "aa": 2, "cc": 1}, [("aa", 2), ("bb", 2), ("cc", 1)]),
        ({}, []),  # –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å
        ({"x": 5}, [("x", 5)]),
    ],
)
def test_top_n(source, expected):
    assert top_n(source) == expected
```
### —Ç–µ—Ä–º–∏–Ω–∞–ª:
![–í—ã–≤–æ–¥:](./images/lab07/test_nb.png)


![–í—ã–≤–æ–¥:](./images/lab07/test_tb.png)

![–í—ã–≤–æ–¥:](./images/lab07/test_cf.png)

![–í—ã–≤–æ–¥:](./images/lab07/test_tn.png)



## —Ñ–∞–π–ª test_json_csv.py
```python
import pytest
import json
import csv
from pathlib import Path
from src.lab05.json_csv import json_to_csv, csv_to_json


# –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏
@pytest.mark.parametrize(
    "json_data, csv_fieldnames",
    [
        ([{"name": "Alice", "age": 22}, {"name": "Bob", "age": 25}], ["name", "age"]),
        ([{"item": "apple", "qty": 10}, {"item": "banana", "qty": 5}], ["item", "qty"]),
    ],
)
def test_json_to_csv_roundtrip(tmp_path: Path, json_data, csv_fieldnames):
    src_json = tmp_path / "src.json"
    dst_csv = tmp_path / "out.csv"
    roundtrip_json = tmp_path / "roundtrip.json"

    src_json.write_text(
        json.dumps(json_data, ensure_ascii=False, indent=2), encoding="utf-8"
    )

    # JSON -> CSV
    json_to_csv(str(src_json), str(dst_csv))
    assert dst_csv.exists()

    # CSV -> JSON
    csv_to_json(str(dst_csv), str(roundtrip_json))
    assert roundtrip_json.exists()

    # –ø—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –∏ –∫–ª—é—á–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç
    with roundtrip_json.open(encoding="utf-8") as f:
        data_after = json.load(f)
    assert len(data_after) == len(json_data)
    for record in data_after:
        assert set(csv_fieldnames) <= set(record.keys())


# –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏
@pytest.mark.parametrize(
    "write_content, func",
    [
        ("", json_to_csv),  # –ø—É—Å—Ç–æ–π JSON
        ("{not: valid}", json_to_csv),  # –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON
        ("", csv_to_json),  # –ø—É—Å—Ç–æ–π CSV
        ("name,age\nAlice", csv_to_json),  # –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π CSV
    ],
)
def test_invalid_files(tmp_path: Path, write_content, func):
    src = tmp_path / "input.file"
    dst = tmp_path / "output.file"
    src.write_text(write_content, encoding="utf-8")
    with pytest.raises(ValueError):
        func(str(src), str(dst))


@pytest.mark.parametrize("func", [json_to_csv, csv_to_json])
def test_nonexistent_file(tmp_path: Path, func):
    src = tmp_path / "does_not_exist.file"
    dst = tmp_path / "output.file"
    with pytest.raises(FileNotFoundError):
        func(str(src), str(dst))
```
### —Ç–µ—Ä–º–∏–Ω–∞–ª:
![–í—ã–≤–æ–¥:](./images/lab07/test_jtcr.png)

![–í—ã–≤–æ–¥:](./images/lab07/test_if.png)

![–í—ã–≤–æ–¥:](./images/lab07/test_nf.png)



## –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–æ–¥–∞ —Å—Ç–∏–ª—é black:

![–í—ã–≤–æ–¥:](./images/lab07/black.png) 

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 8
## —Ñ–∞–π–ª models.py:
```python
from dataclasses import dataclass    
from datetime import datetime, date
@dataclass
class Student:
    fio: str 
    birthdate: str 
    group: str 
    gpa: float 

    def __post_init__(self):
        try:
            datetime.strptime(self.birthdate, "%Y-%m-%d")
        except ValueError:
            raise ValueError(
                f"–Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã —Ä–∂–¥–µ–Ω–∏—è: '{self.birthdate}'. "
                "–æ–∂–∏–¥–∞–µ—Ç—Å—è: YYYY-MM-DD"
            )
        if not (0 <= self.gpa <= 5):
            raise ValueError(f"GPA –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 0-5, –ø–æ–ª—É—á–µ–Ω: {self.gpa}")
        
    def age(self) -> int:
        birth = datetime.strptime(self.birthdate, "%Y-%m-%d").date()
        today = date.today()
        years = today.year - birth.year
        if (today.month, today.day) < (birth.month, birth.day):
            years -= 1
        return years

    def to_dict(self) -> dict:
        if not all([self.fio, self.birthdate, self.group, self.gpa is not None]):
            raise ValueError("–Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–æ–ª—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")
        if not isinstance(self.fio, str):
            raise TypeError(f"–§–ò–û –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π, –ø–æ–ª—É—á–µ–Ω–æ: {type(self.fio).__name__}")
        if not isinstance(self.birthdate, str):
            raise TypeError(f"–î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π, –ø–æ–ª—É—á–µ–Ω–æ: {type(self.birthdate).__name__}")
        if not isinstance(self.group, str):
            raise TypeError(f"–≥—Ä—É–ø–ø–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π, –ø–æ–ª—É—á–µ–Ω–æ: {type(self.group).__name__}")
        if not isinstance(self.gpa, (int, float)):
            raise TypeError(f"GPA –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —á–∏—Å–ª–æ–º, –ø–æ–ª—É—á–µ–Ω–æ: {type(self.gpa).__name__}")
        
        if not (0 <= self.gpa <= 5):
            raise ValueError(f"gpa must be between 0 and 5, got {self.gpa}")
        try:
            datetime.strptime(self.birthdate, "%Y-%m-%d")
        except ValueError:
            raise ValueError(
                f"birthdate format must be YYYY-MM-DD, got {self.birthdate}"
            )
        return {
            "fio": self.fio,
            "birthdate": self.birthdate,
            "group": self.group,
            "gpa": self.gpa
        }
    @classmethod
    def from_dict(clss, d: dict):
        return clss(
            fio=d.get("fio"),
            birthdate=d.get("birthdate"),
            group=d.get("group"),
            gpa=d.get("gpa"),
        )

    def __str__(self):
        return f"{self.fio}, {self.group}, GPA: {self.gpa}"

```

## —Ñ–∞–π–ª serialize.py:
```python
import json
from typing import List
from .models import Student


def save_students_to_json(path: str, students: List[Student]):
    data = [s.to_dict() for s in students]
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=4, ensure_ascii=False)


def load_students_from_json(path: str) -> List[Student]:
    with open(path, "r", encoding="utf-8") as f:
        data = json.load(f)
    return [Student.from_dict(item) for item in data]


if __name__ == "__main__":
    students = load_students_from_json("data/lab08/students_input.json")
    save_students_to_json("data/lab08/students_output.json", students)
    print("—Å—Ç—É–¥–µ–Ω—Ç—ã, –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –∏–∑ students_input.json:")
    for student in students:
        print(student)
```

### —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ –æ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤: 

![–í—ã–≤–æ–¥:](./images/lab08/terminal.png)



### –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ —Å—Ç–∏–ª—é Black

![–í—ã–≤–æ–¥:](./images/lab08/stile.png)

